{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLOps with datalab\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1 What is MLOps?\n",
    "\n",
    "**MLOps** stands for `Machine Learning Operations`. It contains a set of best practices that seeks to increase automation and improve the efficiency of models development and deployment.\n",
    "\n",
    "### 1.2 Why do we need MLOps? Git is not enough?\n",
    "\n",
    "Put a machine learning model into production is difficult. It envoles many complex aspects such as\n",
    "- data collection/ingest,\n",
    "- data prep (e.g. cleaning, feature engineering, etc),\n",
    "- model development\n",
    "- model training,\n",
    "- model tuning\n",
    "- model deployment\n",
    "- model monitoring,\n",
    "- model explainability\n",
    "- ETC.\n",
    "\n",
    "Below figure shows the different aspects of mlops :\n",
    "\n",
    "![ml_technical_debt.PNG](img/ml_technical_debt.PNG)\n",
    "\n",
    "### 1.3 ML Operations\n",
    "\n",
    "We need to address the following MLOps principals:\n",
    "\n",
    "- **Model tracking**: track all the necessary element to reproduce the model such as code, hyperparameter and training data.\n",
    "- **Model review**: evaluate model and produce report.\n",
    "- **Model Governance** : manage model versions, model artifacts and transitions through their lifecycle (e.g. staging, production, archived,etc.).\n",
    "\n",
    "- **Model delivery/deployment**: Automate the process of model devlivery/deployment (e.g. permissions, server creation, API management, etc.)\n",
    "- **Model monitoring**: Monitor the state of model production server (e.g. number of request, response time, serving data anomalies, etc.)\n",
    "- **Model retraining**: Retrain model in case of **model drift** due to differences in training and inference data or `data evolution`.\n",
    "\n",
    "\n",
    "### 1.4 Continuous X\n",
    "\n",
    "- **CI**: Track all information of model (e.g. code, training data prepartion, hyper-parameters optimization)\n",
    "- **CD**: Deliver models with their complete training pipeline. \n",
    "- **CT(Continuous training)**: Models need to be retrained automatically. Because evolving data make your model decay. data validation is essential at this step, Because data drifting can be caused by evolution or errors.\n",
    "\n",
    "For more information about MLops, you can visit this [page](README.md) \n",
    "\n",
    "## 2 Illustrate mlops via a application example\n",
    "\n",
    "## 2.1 The context\n",
    "\n",
    "If you are a pokemon go player, when you capture a new pokemon, you may want to know if this pokemon is good or not. To make this easier, we would like to train a classification model that can tell us if the pokemon is legendary or not.\n",
    "\n",
    "In this tutorial we will use a random forest classifier to implement this model\n",
    "\n",
    "## 2.2 Prepare environment and install the dependencies\n",
    "\n",
    "Launch a jupyter service in datalab.\n",
    "\n",
    "**Don't forget to assign admin role in kubernetes tab**\n",
    "\n",
    "![jupyter_datalab.PNG](img/jupyter_datalab.PNG)\n",
    "\n",
    "Start a terminal in jupyter\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/pengfei99/MLOPS.git\n",
    "```\n",
    "\n",
    "Then install the dependencies\n",
    "\n",
    "```shell\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 0. EDA and feature engnieering on training data\n",
    "\n",
    "After EDA and feature engnieering, we select below colums as features\n",
    "- hp\n",
    "- attack\n",
    "- defence\n",
    "- special_attack\n",
    "- special_defenece\n",
    "- speed\n",
    "\n",
    "and column **legendary** as label.\n",
    "\n",
    "For more details on feature engnieering, please visit this [repo](https://github.com/pengfei99/FeatureEngineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training data path\n",
    "data_url = \"https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\"\n",
    "raw_df = pd.read_csv(data_url, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name               object\n",
       "type_1             object\n",
       "type_2             object\n",
       "total               int64\n",
       "hp                  int64\n",
       "attack              int64\n",
       "defense             int64\n",
       "special_attack      int64\n",
       "special_defense     int64\n",
       "speed               int64\n",
       "generation          int64\n",
       "legendary            bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>total</th>\n",
       "      <th>hp</th>\n",
       "      <th>attack</th>\n",
       "      <th>defense</th>\n",
       "      <th>special_attack</th>\n",
       "      <th>special_defense</th>\n",
       "      <th>speed</th>\n",
       "      <th>generation</th>\n",
       "      <th>legendary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name type_1  type_2  total  hp  attack  defense  \\\n",
       "index                                                                     \n",
       "1                  Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "2                    Ivysaur  Grass  Poison    405  60      62       63   \n",
       "3                   Venusaur  Grass  Poison    525  80      82       83   \n",
       "3      VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4                 Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "       special_attack  special_defense  speed  generation  legendary  \n",
       "index                                                                 \n",
       "1                  65               65     45           1      False  \n",
       "2                  80               80     60           1      False  \n",
       "3                 100              100     80           1      False  \n",
       "3                 122              120     80           1      False  \n",
       "4                  60               50     65           1      False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Phase 1. Train a model in an old school way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate an accuracy from the confusion matrix\n",
    "def get_model_accuracy(cf_matrix):\n",
    "    diagonal_sum = cf_matrix.trace()\n",
    "    sum_of_all_elements = cf_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "# main logic for model training\n",
    "def train_model(data_url: str, n_estimator: int, max_depth: int, min_samples_split: int):\n",
    "    print(f\"data source: {data_url}\")\n",
    "    feature_data, label_data = prepare_data(data_url)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(feature_data, label_data, train_size=0.8, test_size=0.2,\n",
    "                                                        random_state=0)\n",
    "    # print(len(test_X))\n",
    "\n",
    "    # create a random forest classifier\n",
    "    rf_clf = RandomForestClassifier(n_estimators=n_estimator, max_depth=max_depth,\n",
    "                                    min_samples_split=min_samples_split,\n",
    "                                    n_jobs=2, random_state=0)\n",
    "    # train the model with training_data\n",
    "    rf_clf.fit(train_X, train_y)\n",
    "    # predict testing data\n",
    "    predicts_val = rf_clf.predict(test_X)\n",
    "\n",
    "    # Generate a cm\n",
    "    cm = confusion_matrix(test_y, predicts_val)\n",
    "    model_accuracy = get_model_accuracy(cm)\n",
    "    print(\"RandomForest model with hyper-parameters: (n_estimator=%f, max_depth=%f, min_samples_split=%f):\" % (\n",
    "        n_estimator, max_depth, min_samples_split))\n",
    "    print(\"accuracy: %f\" % model_accuracy)\n",
    "\n",
    "\n",
    "# data preparation\n",
    "def prepare_data(data_url):\n",
    "    # read data as df\n",
    "    try:\n",
    "        input_df = pd.read_csv(data_url, index_col=0)\n",
    "        input_df.head()\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            \"Unable to read data from the giving path, check your data location. Error: %s\", e\n",
    "        )\n",
    "    # Prepare data for ml model\n",
    "    label = input_df.legendary\n",
    "    feature = input_df.drop(['legendary', 'generation', 'total'], axis=1).select_dtypes(exclude=['object'])\n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data source: https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\n",
      "RandomForest model with hyper-parameters: (n_estimator=50.000000, max_depth=50.000000, min_samples_split=2.000000):\n",
      "accuracy: 0.925000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "\n",
    "# set the hyper parameters\n",
    "n_estimator = 50 # The number of trees in the forest.\n",
    "max_depth = 50 # The maximum depth of the tree\n",
    "min_samples_split = 2 # The minimum number of samples required to split an internal node\n",
    "\n",
    "# train the model\n",
    "train_model(data_url, n_estimator, max_depth, min_samples_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Phase 2. Train a model with model tracking tools (CI)\n",
    "\n",
    "In this tutorial, we use mlflow as our model tracking tools. Before you start the phase 2, you need to launch the [mlflow](https://mlflow.org/) service in datalab.\n",
    "\n",
    "\n",
    "![mlflow_datalab.PNG](img/mlflow_datalab.PNG)\n",
    "\n",
    "**Don't forget to disable IP protection**, otherwise you can not fetch trained model from the server.\n",
    "![mlflow_ip_protection.PNG](img/mlflow_ip_protection.PNG)\n",
    "\n",
    "Once you launched the mlflow service you need to create an experiment(project) if you don't have one. The name of the experiment is important, because we will need it to setup a mlflow context. The following code is an example on how to track your model and upload the information to mlflow server,\n",
    " 1. create a mlflow context\n",
    " 2. track training data source\n",
    " 3. track hyperparameter\n",
    " 4. track metric\n",
    " 5. track model binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_with_mlflow_tracking(mlflow_experiment_name: str, mlflow_run_name: str, data_url: str, n_estimator: int,\n",
    "                                     max_depth: int,\n",
    "                                     min_samples_split: int):\n",
    "\n",
    "    feature_data, label_data = prepare_data(data_url)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(feature_data, label_data, train_size=0.8, test_size=0.2,\n",
    "                                                        random_state=0)\n",
    "    # 1.set up mlflow context\n",
    "    mlflow.set_experiment(mlflow_experiment_name)\n",
    "    with mlflow.start_run(run_name=mlflow_run_name):\n",
    "        rf_clf = RandomForestClassifier(n_estimators=n_estimator, max_depth=max_depth,\n",
    "                                        min_samples_split=min_samples_split,\n",
    "                                        n_jobs=2, random_state=0)\n",
    "        rf_clf.fit(train_X, train_y)\n",
    "        predicts_val = rf_clf.predict(test_X)\n",
    "\n",
    "        cm = confusion_matrix(test_y, predicts_val)\n",
    "        model_accuracy = get_model_accuracy(cm)\n",
    "        print(\"RandomForest model with hyper-parameters: (n_estimator=%f, max_depth=%f, min_samples_split=%f):\" % (\n",
    "            n_estimator, max_depth,\n",
    "            min_samples_split))\n",
    "        print(\"accuracy: %f\" % model_accuracy)\n",
    "        # 2. track the training data\n",
    "        mlflow.log_param(\"data_url\", data_url)\n",
    "        # 3. track the hyper-parameters to the mlflow server\n",
    "        mlflow.log_param(\"n_estimator\", n_estimator)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "\n",
    "        # log shap feature explanation extension. This will generate a graph of feature importance of the model\n",
    "        # mlflow.shap.log_explanation(rf_clf.predict, test_X.sample(70))\n",
    "\n",
    "        # 4. track metric\n",
    "        mlflow.log_metric(\"model_accuracy\", model_accuracy)\n",
    "\n",
    "        # 5. track model binary\n",
    "        mlflow.sklearn.log_model(rf_clf, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To make the model training more flexible, we also convert the above jupyter notebook to a python script. Fot the full code, please check [here](tutorials/pokemon/train_model.py)\n",
    "\n",
    "And we write a little bash script to run the python with specific env var. You can edit the script [here](tutorials/pokemon/bash_command/local_run.sh).\n",
    "\n",
    "**You need to modify the configuration such as MLFLOW_TRACKING_URI to your own mlflow server uri to make the script work**\n",
    "\n",
    "```shell\n",
    "#! /bin/bash\n",
    "export MLFLOW_S3_ENDPOINT_URL='https://minio.lab.sspcloud.fr'\n",
    "export MLFLOW_TRACKING_URI='https://user-pengfei-866801.kub.sspcloud.fr/'\n",
    "export MLFLOW_EXPERIMENT_NAME=\"pokemon\"\n",
    "\n",
    "run_name=\"default\"\n",
    "data_url=\"https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\"\n",
    "\n",
    "# set the hyper parameters\n",
    "n_estimator=\"50\"\n",
    "max_depth=\"30\"\n",
    "min_samples_split=\"2\"\n",
    "\n",
    "root_path=\"/home/jovyan/work/MLOPS\"\n",
    "\n",
    "python ${root_path}/tutorials/pokemon/train_model.py ${MLFLOW_EXPERIMENT_NAME} ${run_name} ${data_url} ${n_estimator} ${max_depth} ${min_samples_split}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest model with hyper-parameters: (n_estimator=50.000000, max_depth=30.000000, min_samples_split=2.000000):\n",
      "accuracy: 0.925000\n",
      "100%|███████████████████████████████████████████| 70/70 [00:06<00:00, 11.45it/s]\n"
     ]
    }
   ],
   "source": [
    "! sh tutorials/pokemon/bash_command/local_run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After you run the above command, all the tracking information of the model will be uploaded to the target mlflow server.\n",
    "\n",
    "Below figure shows the architecture:\n",
    "\n",
    "![local_training_archi.png](img/local_training_archi.png)\n",
    "\n",
    "But we still need to set up the python `virtual environment` and git clone the code, can we do better?\n",
    "\n",
    "Yes, we can. Thanks to the mlflow, which offers a launching API which can build the virtual environment and get the code automatically.\n",
    "\n",
    "We only need to setup two config files\n",
    "- MLproject (**This file must be at the root path of your git repo, otherwise mlflow can't run the workflow**)\n",
    "- conda.yaml\n",
    "\n",
    "Below is our [MLporject](MLproject):\n",
    "```yaml\n",
    "name: pokemon-legendary-estimator\n",
    "\n",
    "conda_env: tutorials/pokemon/conda.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      remote_server_uri: {type: str, default: http://pengfei.org:8000}\n",
    "      experiment_name: {type: str, default: test-1}\n",
    "      run_name: {type: str, default: default}\n",
    "      data_url: {type: str, default: https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv}\n",
    "      n_estimator: {type: int, default: 10}\n",
    "      max_depth: {type: int, default: 5}\n",
    "      min_samples_split: {type: int, default: 2}\n",
    "    command: \"python tutorials/pokemon/train_model.py {experiment_name} {run_name} {data_url} {n_estimator} {max_depth} {min_samples_split}\"\n",
    "```\n",
    "\n",
    "and [conda.yaml](tutorials/pokemon/conda.yaml)\n",
    "\n",
    "```yaml\n",
    "name: pokemon-legendary-estimator\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - pip\n",
    "  - pip:\n",
    "    - scikit-learn==1.1.2\n",
    "    - mlflow>=1.28.0\n",
    "    - pandas>=1.2.2\n",
    "    - numpy>=1.20.1\n",
    "    - shap>=0.39.0\n",
    "    - matplotlib>=3.4.1\n",
    "    - boto3==1.17.19\n",
    "```\n",
    "\n",
    "And now we can train a model without installing anything with below bash script. You can edit the script [here](tutorials/pokemon/bash_command/remote_run.sh).\n",
    "\n",
    "**You need to replace the configuration such as MLFLOW_TRACKING_URI to your own mlflow server uri to make the script work**\n",
    "\n",
    "```shell\n",
    "#! /bin/bash\n",
    "export MLFLOW_S3_ENDPOINT_URL='https://minio.lab.sspcloud.fr'\n",
    "export MLFLOW_TRACKING_URI='https://user-pengfei-866801.kub.sspcloud.fr/'\n",
    "export MLFLOW_EXPERIMENT_NAME=\"pokemon\"\n",
    "\n",
    "run_name=\"default\"\n",
    "data_url=\"https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\"\n",
    "\n",
    "# set the hyper parameters\n",
    "n_estimator=\"50\"\n",
    "max_depth=\"30\"\n",
    "min_samples_split=\"2\"\n",
    "\n",
    "mlflow run https://github.com/pengfei99/MLOPS.git -P remote_server_uri=${MLFLOW_TRACKING_URI} \\\n",
    "-P experiment_name=${MLFLOW_EXPERIMENT_NAME} \\\n",
    "-P data_url=${data_url} \\\n",
    "-P n_estimator=${n_estimator} -P max_depth=${max_depth} -P min_samples_split=${min_samples_split}\n",
    "```\n",
    "\n",
    "Now, you can see we let the mlflow download the code and create virtual environment for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! sh tutorials/pokemon/bash_command/remote_run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Phase 3 Train many models in parallel (CI)\n",
    "\n",
    "After Phase 2, we can track all information to reproduce a model, but it will take long time to compare many hyper-parameter combinations, if we can only train a model one by one. If we can train the model in parallel, then we can shorten the development time of the model.\n",
    "\n",
    "To do so, we need to launch a new service called [argo workflow](https://argoproj.github.io/argo-workflows/) in datalab\n",
    "\n",
    "![argo_datalab.PNG](img/argo_datalab.PNG)\n",
    "\n",
    "When you launch the argo-workflow service, pay attention to the `service account` value, because this service will need to launch new pods in the cluster k8s, which requires special rights, and this service account will give you the rights.\n",
    "\n",
    "Now let's check the workflow specification ([workflow.yaml](tutorials/pokemon/argo_workflow/workflow.yaml)).\n",
    "\n",
    "It can be dived into three parts:\n",
    "1. Workflow configuration\n",
    "2. Workflow DAG ([Directed acyclic graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph)) planing\n",
    "3. Task logic implementation of the workflow dag\n",
    "\n",
    "**We need to configure the workflow parameter** before launching the workflow such as:\n",
    "- minio creds\n",
    "- mlflow uri\n",
    "- model git repo uri\n",
    "- etc.\n",
    "\n",
    "## 3.1 Installation of the argo workflow client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! sudo sh tutorials/pokemon/bash_command/argo_deb_install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check the client version\n",
    "! argo version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Run the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! argo submit tutorials/pokemon/argo_workflow/workflow.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also check the workflow progress via the argo workflow web interface\n",
    "\n",
    "Below figure shows the architecture of what just happened\n",
    "![multi_model_training_archi_overview.png](img/multi_model_training_archi_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Phase 4 Model management\n",
    "\n",
    "## 4.1 Model evaluation\n",
    "Now we have trained many models, we need to find the best model and deploy it into production.\n",
    "\n",
    "Mlflow allow us to compare model accuracy based on different hyperparameters. Below figure is an example\n",
    "\n",
    "![mlflow_model_eval.PNG](img/mlflow_model_eval.PNG)\n",
    "\n",
    "## 4.2 Model delivery\n",
    "\n",
    "After we find our target model, we can publish it to our model registry with a version number and state\n",
    "- production\n",
    "- staging\n",
    "- archived\n",
    "\n",
    "Below figure shows an example of the model registry\n",
    "![mlflow_model_version.PNG](img/mlflow_model_version.PNG)\n",
    "\n",
    "\n",
    "## 4.3 Consuming the model,\n",
    "\n",
    "Once the model is published in the model registry, it can be consumed by using the mlflow api. In below code, we use the `mlflow.pyfunc.load_model` function to fetch a trained model from the mlflow server.\n",
    "\n",
    "```python\n",
    "\n",
    "def fetch_model(server_uri: str, experiment_name: str, model_version: str):\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = server_uri\n",
    "    # fetch the trained model from mlflow server by using its version\n",
    "    model = mlflow.pyfunc.load_model(model_uri=f\"models:/{experiment_name}/{model_version}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(server_uri: str, experiment_name: str, model_version: str):\n",
    "    # step1: prepare sample data\n",
    "    legendary_sample, normal_sample = prepare_sample_data()\n",
    "\n",
    "    # step2: fetch the model\n",
    "    model = fetch_model(server_uri, experiment_name, model_version)\n",
    "    \n",
    "    # step3: predict the sample data\n",
    "    print(f\"The prediction of 5 five legendary pokemon: {model.predict(legendary_sample)}\")\n",
    "    print(f\"The prediction of 5 five normal pokemon: {model.predict(normal_sample)}\")\n",
    "```\n",
    "\n",
    "The complete source code of `fetch_model.py` can be found [here](tutorials/pokemon/fetch_model.py)\n",
    "\n",
    "The launching script can be found [here](tutorials/pokemon/bash_command/fetch_model_run.sh)\n",
    "\n",
    "**Don't forget to replace the MLFLOW_TRACKING_URI by our own value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legendary pokemon samples:\n",
      "         hp  attack  defense  special_attack  special_defense  speed\n",
      "index                                                              \n",
      "484     90     120      100             150              120    100\n",
      "386     50     180       20             180               20    150\n",
      "383    100     180      160             150               90     90\n",
      "493    120     120      120             120              120    120\n",
      "494    100     100      100             100              100    100\n",
      "normal pokemon samples:\n",
      "        hp  attack  defense  special_attack  special_defense  speed\n",
      "index                                                             \n",
      "122    40      45       65             100              120     90\n",
      "98     30     105       90              25               25     50\n",
      "682    78      52       60              63               65     23\n",
      "457    69      69       76              69               86     91\n",
      "566    55     112       45              74               45     70\n",
      "2022/09/19 13:27:16 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - scikit-learn (current: 1.1.1, required: scikit-learn==0.24.1)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2022/09/19 13:27:16 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.8.13`, differs from the version of Python that is currently running, `Python 3.9.12`, and may be incompatible\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.1 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.1 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "The prediction of 5 five legendary pokemon: [ True False  True  True  True]\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "The prediction of 5 five normal pokemon: [False False False False False]\n"
     ]
    }
   ],
   "source": [
    "! sh tutorials/pokemon/bash_command/fetch_model_run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5 Model deployment (CD)\n",
    "\n",
    "In the above section, we have seen how to consume a published model. But we have to still run the code, it's not very practical for the users. So we want to expose our model as a Rest Api and when the model is updated, the api is updated automatically.\n",
    "\n",
    "## 5.1 First step: Build Rest Api\n",
    "We need to build a Rest Api by fetching the trained model, it's not the main goal of this tutorial. For more information on how to build a Rest Api, you can visit this [git repo](https://github.com/pengfei99/PokemonDTCAPI.git)\n",
    "\n",
    "## 5.2 Second step: Create a k8s deployment of the Rest Api\n",
    "\n",
    "Now we need to create a k8s deployment of the Rest api. The deployment configuration contais three files:\n",
    "- deployment.yaml : It runs multiple replicas of our **model API** and automatically replaces any instances that fail or become unresponsive.\n",
    "- service.yaml : It exposes our model API on Pods as a network service.\n",
    "- ingress.yaml : It manages external access to the services via HTTP (e.g. url, ssl, etc.).\n",
    "\n",
    "You can find the full code of the three files [here](tutorials/pokemon/k8s).\n",
    "\n",
    "Before you run the below command, **Don't forget to replace the value of MLFLOW_TRACKING_URI** in the [deployment.yaml](tutorials/pokemon/k8s/deployment.yaml)\n",
    "\n",
    "Now we can try to deploy the model api by using below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/pokemon-model-deployment created\n",
      "ingress.networking.k8s.io/pokemon-model-ingress created\n",
      "service/pokemon-model-service created\n"
     ]
    }
   ],
   "source": [
    "! kubectl apply -f tutorials/pokemon/k8s/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you want to delete it, you can run below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"pokemon-model-deployment\" deleted\n",
      "ingress.networking.k8s.io \"pokemon-model-ingress\" deleted\n",
      "service \"pokemon-model-service\" deleted\n"
     ]
    }
   ],
   "source": [
    "! kubectl delete -f tutorials/pokemon/k8s/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5.3 Third step: Automate the deployment\n",
    "\n",
    "We have finished the manual deployment, now we want to deploy the model automatically when a new model is published.\n",
    "\n",
    "We will need to launch a new service called [argo CD](https://argo-cd.readthedocs.io/en/stable/)\n",
    "\n",
    "![argo_datalab.PNG](img/argo_datalab.PNG)\n",
    "\n",
    "Once you the argo CD is launched, you can create a new app in it.\n",
    "\n",
    "Below is an example of the yaml file to create a new app. You can find it [here](tutorials/pokemon/argocd/pokemon-api-app.yaml)\n",
    "\n",
    "```yaml\n",
    "apiVersion: argoproj.io/v1alpha1\n",
    "kind: Application\n",
    "metadata:\n",
    "  name: pokemon-api\n",
    "spec:\n",
    "  project: default\n",
    "  source:\n",
    "    repoURL: https://github.com/pengfei99/MLOPS.git\n",
    "    targetRevision: HEAD\n",
    "    path: tutorials/pokemon/k8s\n",
    "  destination:\n",
    "    server: https://kubernetes.default.svc\n",
    "    namespace: user-pengfei\n",
    "  syncPolicy:\n",
    "    automated:\n",
    "      selfHeal: true\n",
    "```\n",
    "\n",
    "There are two important part you need to change:\n",
    "1. source: Your repo git url and the path of your k8s deployment code\n",
    "2. destination: k8s api server url and the target namespace\n",
    "\n",
    "After you created the application in argo CD with above config, you should see something like in the below figure\n",
    "![argo_cd_datalab.PNG](img/argo_cd_datalab.PNG)\n",
    "Now, argo CD will watch your git repo, every 5 mins, it will compare the code in `tutorials/pokemon/k8s` (git repo) with the currently deployed version. If an update is detected, argo CD will deploy the updated model automatically for us.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. It's your turn now\n",
    "\n",
    "Try to reproduce the above step and deploy your own model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

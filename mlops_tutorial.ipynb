{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLOps with datalab\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1 What is MLOps?\n",
    "\n",
    "**MLOps** stands for `Machine Learning Operations`. It contains a set of best practices that seeks to increase automation and improve the efficiency of models development and deployment.\n",
    "\n",
    "### 1.2 Why do we need MLOps? Git is not enough?\n",
    "\n",
    "Put a machine learning model into production is difficult. It envoles many complex aspects such as\n",
    "- data collection/ingest,\n",
    "- data prep (e.g. cleaning, feature engineering, etc),\n",
    "- model development\n",
    "- model training,\n",
    "- model tuning\n",
    "- model deployment\n",
    "- model monitoring,\n",
    "- model explainability\n",
    "- ETC.\n",
    "\n",
    "Below figure shows the different aspects of mlops :\n",
    "\n",
    "![ml_technical_debt.PNG](img/ml_technical_debt.PNG)\n",
    "\n",
    "### 1.3 ML Operations\n",
    "\n",
    "We need to address the following MLOps principals:\n",
    "\n",
    "- **Model tracking**: track all the necessary element to reproduce the model such as code, hyperparameter and training data.\n",
    "- **Model review**: Test model and produce quality assurance report. Inference model production-specifics properties such as model response times.\n",
    "- **Model Governance** : manage model versions, model artifacts and transitions through their lifecycle (e.g. staging, production, archived,etc.).\n",
    "\n",
    "- **Model deployment**: Automate the process of deploying registered models (e.g. permissions, cluster creation, API management, etc.)\n",
    "- **Model monitoring**: Monitor the state of model production server (e.g. number of request, response time, serving data anomalies, etc.)\n",
    "- **Model retraining**: Create alerts and automation to take corrective action in case of **model drift** due to\n",
    "                    differences in training and inference data or `data evolution`.\n",
    "\n",
    "\n",
    "### 1.4 Continuous X\n",
    "\n",
    "- **CI**: Track model code, training data( e.g. Feature engineering/selection), hyper-parameters optimization\n",
    "- **CD**: Need to deliver not only an executable package, but also a complete pipeline of how the model is trained.\n",
    "- **CT(Continuous training)**: Models need to be retrained automatically. Because evolving data make your model decay. data validation is essential at this step, Because data drifting can be caused by evolution or errors.\n",
    "\n",
    "## 2 Illustrate mlops via a application example\n",
    "\n",
    "## 2.1 The context\n",
    "\n",
    "If you are a pokemon go player, when you capture a new pokemon, you may want to know if this pokemon is good or not. To make this easier, we would like to train a classification model that can tell us if the pokemon is legendary or not.\n",
    "\n",
    "In this tutorial we will use a random forest classifier to implement this model\n",
    "\n",
    "## 2.2 Prepare environment and install the dependencies\n",
    "\n",
    "Launch a jupyter service in datalab.\n",
    "\n",
    "**Don't forget to assign admin role in kubernetes tab**\n",
    "\n",
    "![jupyter_datalab.PNG](img/jupyter_datalab.PNG)\n",
    "\n",
    "Start a terminal in jupyter\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/pengfei99/MLOPS.git\n",
    "```\n",
    "\n",
    "Then install the dependencies\n",
    "\n",
    "```shell\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Phase 1. Train a model in an old school way"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# calculate an accuracy from the confusion matrix\n",
    "def get_model_accuracy(cf_matrix):\n",
    "    diagonal_sum = cf_matrix.trace()\n",
    "    sum_of_all_elements = cf_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "\n",
    "def train_model(data_url: str, n_estimator: int, max_depth: int, min_samples_split: int):\n",
    "    print(f\"data source: {data_url}\")\n",
    "    feature_data, label_data = prepare_data(data_url)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(feature_data, label_data, train_size=0.8, test_size=0.2,\n",
    "                                                        random_state=0)\n",
    "    # print(len(test_X))\n",
    "\n",
    "    # create a random forest classifier\n",
    "    rf_clf = RandomForestClassifier(n_estimators=n_estimator, max_depth=max_depth,\n",
    "                                    min_samples_split=min_samples_split,\n",
    "                                    n_jobs=2, random_state=0)\n",
    "    # train the model with training_data\n",
    "    rf_clf.fit(train_X, train_y)\n",
    "    # predict testing data\n",
    "    predicts_val = rf_clf.predict(test_X)\n",
    "\n",
    "    # Generate a cm\n",
    "    cm = confusion_matrix(test_y, predicts_val)\n",
    "    model_accuracy = get_model_accuracy(cm)\n",
    "    print(\"RandomForest model with hyper-parameters: (n_estimator=%f, max_depth=%f, min_samples_split=%f):\" % (\n",
    "        n_estimator, max_depth, min_samples_split))\n",
    "    print(\"accuracy: %f\" % model_accuracy)\n",
    "\n",
    "\n",
    "def prepare_data(data_url):\n",
    "    # read data as df\n",
    "    try:\n",
    "        input_df = pd.read_csv(data_url, index_col=0)\n",
    "        input_df.head()\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            \"Unable to read data from the giving path, check your data location. Error: %s\", e\n",
    "        )\n",
    "    # Prepare data for ml model\n",
    "    label = input_df.legendary\n",
    "    feature = input_df.drop(['legendary', 'generation', 'total'], axis=1).select_dtypes(exclude=['object'])\n",
    "    return feature, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data source: https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\n",
      "RandomForest model with hyper-parameters: (n_estimator=50.000000, max_depth=30.000000, min_samples_split=2.000000):\n",
      "accuracy: 0.925000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "# set the training data path\n",
    "data_url = \"https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\"\n",
    "\n",
    "# set the hyper parameters\n",
    "n_estimator = 50\n",
    "max_depth = 30\n",
    "min_samples_split = 2\n",
    "\n",
    "# train the model\n",
    "train_model(data_url, n_estimator, max_depth, min_samples_split)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Phase 2. Train a model with model tracking tools (CI)\n",
    "\n",
    "In this tutorial, we use mlflow as our model tracking tools. Before you start the phase 2, you need to launch the [mlflow](https://mlflow.org/) service in datalab\n",
    "\n",
    "![mlflow_datalab.PNG](img/mlflow_datalab.PNG)\n",
    "\n",
    "Once you launched the mlflow service you need to create an experiment(project) if you don't have one. The name of the experiment is important, because we will need it to setup a mlflow context. The following code is an example on how to track your model and upload the information to mlflow server,\n",
    " 1. create a mlflow context\n",
    " 2. track training data source\n",
    " 3. track hyperparameter\n",
    " 4. track metric\n",
    " 5. track model binary."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model_with_mlflow_tracking(mlflow_experiment_name: str, mlflow_run_name: str, data_url: str, n_estimator: int,\n",
    "                                     max_depth: int,\n",
    "                                     min_samples_split: int):\n",
    "    # Step1: Prepare data\n",
    "    feature_data, label_data = prepare_data(data_url)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(feature_data, label_data, train_size=0.8, test_size=0.2,\n",
    "                                                        random_state=0)\n",
    "    # set up mlflow context\n",
    "    mlflow.set_experiment(mlflow_experiment_name)\n",
    "    with mlflow.start_run(run_name=mlflow_run_name):\n",
    "        # create a random forest classifier\n",
    "        rf_clf = RandomForestClassifier(n_estimators=n_estimator, max_depth=max_depth,\n",
    "                                        min_samples_split=min_samples_split,\n",
    "                                        n_jobs=2, random_state=0)\n",
    "        # train the model with training_data\n",
    "        rf_clf.fit(train_X, train_y)\n",
    "        # predict testing data\n",
    "        predicts_val = rf_clf.predict(test_X)\n",
    "\n",
    "        # Generate a cm\n",
    "        cm = confusion_matrix(test_y, predicts_val)\n",
    "        model_accuracy = get_model_accuracy(cm)\n",
    "        print(\"RandomForest model with hyper-parameters: (n_estimator=%f, max_depth=%f, min_samples_split=%f):\" % (\n",
    "            n_estimator, max_depth,\n",
    "            min_samples_split))\n",
    "        print(\"accuracy: %f\" % model_accuracy)\n",
    "        # log the model hyper-parameters to the mlflow server\n",
    "        mlflow.log_param(\"data_url\", data_url)\n",
    "        mlflow.log_param(\"n_estimator\", n_estimator)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "\n",
    "        # log shap feature explanation extension. This will generate a graph of feature importance of the model\n",
    "        # mlflow.shap.log_explanation(rf_clf.predict, test_X.sample(70))\n",
    "\n",
    "        # log the model accuracy to the mlflow server\n",
    "        mlflow.log_metric(\"model_accuracy\", model_accuracy)\n",
    "\n",
    "        # log the model to the mlflow server\n",
    "        mlflow.sklearn.log_model(rf_clf, \"model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make the model training more flexible, we also convert the above jupyter notebook to a python script. Fot the full code, please check [here](tutorials/pokemon/train_model.py)\n",
    "\n",
    "And we write a little bash script to run the python with specific env var. **You need to modify the configuration such as MLFLOW_TRACKING_URI to your own mlflow server uri to make the script work**\n",
    "\n",
    "```shell\n",
    "#! /bin/bash\n",
    "export MLFLOW_S3_ENDPOINT_URL='https://minio.lab.sspcloud.fr'\n",
    "export MLFLOW_TRACKING_URI='https://user-pengfei-866801.kub.sspcloud.fr/'\n",
    "export MLFLOW_EXPERIMENT_NAME=\"pokemon\"\n",
    "\n",
    "run_name=\"default\"\n",
    "data_url=\"https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\"\n",
    "\n",
    "# set the hyper parameters\n",
    "n_estimator=\"50\"\n",
    "max_depth=\"30\"\n",
    "min_samples_split=\"2\"\n",
    "\n",
    "root_path=\"/home/jovyan/work/MLOPS\"\n",
    "\n",
    "python ${root_path}/tutorials/pokemon/train_model.py ${MLFLOW_EXPERIMENT_NAME} ${run_name} ${data_url} ${n_estimator} ${max_depth} ${min_samples_split}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! sh tutorials / pokemon / bash_command / local_run.sh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After you run the above command, all the tracking information of the model will be uploaded to the target mlflow server.\n",
    "\n",
    "Below figure shows the architecture:\n",
    "\n",
    "![local_training_archi.png](img/local_training_archi.png)\n",
    "\n",
    "But we still need to set up the python `virtual environment` and git clone the code, can we do better?\n",
    "\n",
    "Yes, we can. Thanks to the mlflow, which offers a launching API which can build the virtual environment and get the code automatically.\n",
    "\n",
    "We only need to setup two config files\n",
    "- MLproject (**This file must be at the root path of your git repo, otherwise mlflow can't run the workflow**)\n",
    "- conda.yaml\n",
    "\n",
    "Below is our [MLporject](MLproject):\n",
    "```yaml\n",
    "name: pokemon-legendary-estimator\n",
    "\n",
    "conda_env: tutorials/pokemon/conda.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      remote_server_uri: {type: str, default: http://pengfei.org:8000}\n",
    "      experiment_name: {type: str, default: test-1}\n",
    "      run_name: {type: str, default: default}\n",
    "      data_url: {type: str, default: https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv}\n",
    "      n_estimator: {type: int, default: 10}\n",
    "      max_depth: {type: int, default: 5}\n",
    "      min_samples_split: {type: int, default: 2}\n",
    "    command: \"python tutorials/pokemon/train_model.py {experiment_name} {run_name} {data_url} {n_estimator} {max_depth} {min_samples_split}\"\n",
    "```\n",
    "\n",
    "and [conda.yaml](tutorials/pokemon/conda.yaml)\n",
    "\n",
    "```yaml\n",
    "name: pokemon-legendary-estimator\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - pip\n",
    "  - pip:\n",
    "    - scikit-learn==1.1.2\n",
    "    - mlflow>=1.28.0\n",
    "    - pandas>=1.2.2\n",
    "    - numpy>=1.20.1\n",
    "    - shap>=0.39.0\n",
    "    - matplotlib>=3.4.1\n",
    "    - boto3==1.17.19\n",
    "```\n",
    "\n",
    "And now we can train a model without installing anything with below bash script. **You need to modify the configuration such as MLFLOW_TRACKING_URI to your own mlflow server uri to make the script work**\n",
    "\n",
    "```shell\n",
    "#! /bin/bash\n",
    "export MLFLOW_S3_ENDPOINT_URL='https://minio.lab.sspcloud.fr'\n",
    "export MLFLOW_TRACKING_URI='https://user-pengfei-866801.kub.sspcloud.fr/'\n",
    "export MLFLOW_EXPERIMENT_NAME=\"pokemon\"\n",
    "\n",
    "run_name=\"default\"\n",
    "data_url=\"https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\"\n",
    "\n",
    "# set the hyper parameters\n",
    "n_estimator=\"50\"\n",
    "max_depth=\"30\"\n",
    "min_samples_split=\"2\"\n",
    "\n",
    "mlflow run https://github.com/pengfei99/MLOPS.git -P remote_server_uri=${MLFLOW_TRACKING_URI} \\\n",
    "-P experiment_name=${MLFLOW_EXPERIMENT_NAME} \\\n",
    "-P data_url=${data_url} \\\n",
    "-P n_estimator=${n_estimator} -P max_depth=${max_depth} -P min_samples_split=${min_samples_split}\n",
    "```\n",
    "\n",
    "Now, you can see we let the mlflow download the code and create virtual environment for us"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! sh tutorials / pokemon / bash_command / remote_run.sh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Phase 3 Train many models in parallel (CI)\n",
    "\n",
    "After Phase 2, we can track all information to reproduce a model, but it will take long time to compare many hyper-parameter combinations, if we can only train a model one by one. If we can train the model in parallel, then we can shorten the development time of the model.\n",
    "\n",
    "To do so, we need to launch a new service called [argo workflow](https://argoproj.github.io/argo-workflows/) in datalab\n",
    "\n",
    "![argo_datalab.PNG](img/argo_datalab.PNG)\n",
    "\n",
    "When you launch the argo-workflow service, pay attention to the `service account` value, because this service will need to launch new pods in the cluster k8s, which requires special rights, and this service account will give you the rights.\n",
    "\n",
    "Now let's check the workflow specification ([workflow.yaml](tutorials/pokemon/argo_workflow/workflow.yaml)).\n",
    "\n",
    "It can be dived into three parts:\n",
    "1. Workflow configuration\n",
    "2. Workflow dag planing\n",
    "3. Task logic implementation of the workflow dag\n",
    "\n",
    "**We need to configure the workflow parameter** before launching the workflow such as:\n",
    "- minio creds\n",
    "- mlflow uri\n",
    "- model git repo uri\n",
    "- etc.\n",
    "\n",
    "## 3.1 Installation of the argo workflow client"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! sudo sh tutorials / pokemon / bash_command / argo_deb_install.sh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check the client version\n",
    "! argo version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Run the workflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! argo submit tutorials / pokemon / argo_workflow / workflow.yaml --watch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also check the workflow progress via the argo workflow web interface\n",
    "\n",
    "Below figure shows the architecture of what just happened\n",
    "![multi_model_training_archi_overview.png](img/multi_model_training_archi_overview.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Phase 4 Model management\n",
    "\n",
    "## 4.1 Model evaluation\n",
    "Now we have trained many models, we need to find the best model and deploy it into production.\n",
    "\n",
    "Mlflow allow us to compare model accuracy based on different hyperparameters. Below figure is an example\n",
    "\n",
    "![mlflow_model_eval.PNG](img/mlflow_model_eval.PNG)\n",
    "\n",
    "## 4.2 Model delivery\n",
    "\n",
    "After we find our target model, we can publish it to our model registry with a version number and state\n",
    "- production\n",
    "- staging\n",
    "- archived\n",
    "\n",
    "Below figure shows an example of the model registry\n",
    "![mlflow_model_version.PNG](img/mlflow_model_version.PNG)\n",
    "\n",
    "\n",
    "## 4.3 Consuming the model,\n",
    "\n",
    "Once the model is published in the model registry, it can be consumed by using the mlflow api. In below code, we build an rest Api by consuming \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def prepare_sample_data():\n",
    "    # get the data\n",
    "    data_url = \"https://minio.lab.sspcloud.fr/pengfei/sspcloud-demo/pokemon-cleaned.csv\"\n",
    "    input_df = pd.read_csv(data_url, index_col=0)\n",
    "\n",
    "    ## prepare sample data\n",
    "    # Prepare data for ml model testing\n",
    "    legendary_pokemon = input_df[input_df[\"legendary\"] == True]\n",
    "    legendary_pokemon_sample = legendary_pokemon.sample(5).drop(['legendary', 'generation', 'total'],\n",
    "                                                                axis=1).select_dtypes(\n",
    "        exclude=['object'])\n",
    "    normal_pokemon = input_df[input_df[\"legendary\"] == False]\n",
    "    normal_pokemon_sample = normal_pokemon.sample(5).drop(['legendary', 'generation', 'total'], axis=1).select_dtypes(\n",
    "        exclude=['object'])\n",
    "    return legendary_pokemon_sample, normal_pokemon_sample\n",
    "\n",
    "\n",
    "# fetch the trained model from mlflow server by using its version\n",
    "def fetch_model(server_uri: str, experiment_name: str, model_version: str):\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = server_uri\n",
    "    model = mlflow.pyfunc.load_model(model_uri=f\"models:/{experiment_name}/{model_version}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(server_uri: str, experiment_name: str, model_version: str):\n",
    "    # step1: prepare sample data\n",
    "    legendary_sample, normal_sample = prepare_sample_data()\n",
    "\n",
    "    # step2: fetch the model\n",
    "    model = fetch_model(server_uri, experiment_name, model_version)\n",
    "    # step3: predict the sample data\n",
    "    print(model.predict(legendary_sample))\n",
    "    print(model.predict(normal_sample))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NoCredentialsError",
     "evalue": "Unable to locate credentials",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNoCredentialsError\u001B[0m                        Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m experiment_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpokemon\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m version \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m5\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 6\u001B[0m \u001B[43mtest_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmlflow_server_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43mexperiment_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43mversion\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mtest_model\u001B[0;34m(server_uri, experiment_name, model_version)\u001B[0m\n\u001B[1;32m     27\u001B[0m legendary_sample, normal_sample \u001B[38;5;241m=\u001B[39m prepare_sample_data()\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# step2: fetch the model\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mfetch_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_version\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# step3: predict the sample data\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39mpredict(legendary_sample))\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mfetch_model\u001B[0;34m(server_uri, experiment_name, model_version)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch_model\u001B[39m(server_uri: \u001B[38;5;28mstr\u001B[39m, experiment_name: \u001B[38;5;28mstr\u001B[39m, model_version: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     20\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMLFLOW_TRACKING_URI\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m server_uri\n\u001B[0;32m---> 21\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpyfunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodels:/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mexperiment_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmodel_version\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/mlflow/pyfunc/__init__.py:737\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_uri, suppress_warnings, dst_path)\u001B[0m\n\u001B[1;32m    711\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(\n\u001B[1;32m    712\u001B[0m     model_uri: \u001B[38;5;28mstr\u001B[39m, suppress_warnings: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, dst_path: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    713\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PyFuncModel:\n\u001B[1;32m    714\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;124;03m    Load a model stored in Python function format.\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    735\u001B[0m \u001B[38;5;124;03m                     path will be created.\u001B[39;00m\n\u001B[1;32m    736\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 737\u001B[0m     local_path \u001B[38;5;241m=\u001B[39m \u001B[43m_download_artifact_from_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdst_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    739\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m suppress_warnings:\n\u001B[1;32m    740\u001B[0m         _warn_dependency_requirement_mismatches(local_path)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/mlflow/tracking/artifact_utils.py:100\u001B[0m, in \u001B[0;36m_download_artifact_from_uri\u001B[0;34m(artifact_uri, output_path)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;124;03m                    a local output path will be created.\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     99\u001B[0m root_uri, artifact_path \u001B[38;5;241m=\u001B[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001B[0;32m--> 100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_artifact_repository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mroot_uri\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_artifacts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43martifact_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdst_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_path\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/mlflow/store/artifact/models_artifact_repo.py:126\u001B[0m, in \u001B[0;36mModelsArtifactRepository.download_artifacts\u001B[0;34m(self, artifact_path, dst_path)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdownload_artifacts\u001B[39m(\u001B[38;5;28mself\u001B[39m, artifact_path, dst_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;124;03m    Download an artifact file or directory to a local directory if applicable, and return a\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;124;03m    local path for it.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;124;03m    :return: Absolute path of the local filesystem location containing the desired artifacts.\u001B[39;00m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdst_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/mlflow/store/artifact/artifact_repo.py:239\u001B[0m, in \u001B[0;36mArtifactRepository.download_artifacts\u001B[0;34m(self, artifact_path, dst_path)\u001B[0m\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m    231\u001B[0m         message\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    232\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe destination path for downloaded artifacts must be a directory!\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    235\u001B[0m         error_code\u001B[38;5;241m=\u001B[39mINVALID_PARAMETER_VALUE,\n\u001B[1;32m    236\u001B[0m     )\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# Check if the artifacts points to a directory\u001B[39;00m\n\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_is_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    240\u001B[0m     dst_local_path, inflight_downloads \u001B[38;5;241m=\u001B[39m async_download_artifact_dir(\n\u001B[1;32m    241\u001B[0m         src_artifact_dir_path\u001B[38;5;241m=\u001B[39martifact_path, dst_local_dir_path\u001B[38;5;241m=\u001B[39mdst_path\n\u001B[1;32m    242\u001B[0m     )\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/mlflow/store/artifact/artifact_repo.py:77\u001B[0m, in \u001B[0;36mArtifactRepository._is_directory\u001B[0;34m(self, artifact_path)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_is_directory\u001B[39m(\u001B[38;5;28mself\u001B[39m, artifact_path):\n\u001B[0;32m---> 77\u001B[0m     listing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(listing) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/mlflow/store/artifact/s3_artifact_repo.py:158\u001B[0m, in \u001B[0;36mS3ArtifactRepository.list_artifacts\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m    156\u001B[0m paginator \u001B[38;5;241m=\u001B[39m s3_client\u001B[38;5;241m.\u001B[39mget_paginator(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlist_objects_v2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    157\u001B[0m results \u001B[38;5;241m=\u001B[39m paginator\u001B[38;5;241m.\u001B[39mpaginate(Bucket\u001B[38;5;241m=\u001B[39mbucket, Prefix\u001B[38;5;241m=\u001B[39mprefix, Delimiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 158\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m results:\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;66;03m# Subdirectories will be listed as \"common prefixes\" due to the way we made the request\u001B[39;00m\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m result\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCommonPrefixes\u001B[39m\u001B[38;5;124m\"\u001B[39m, []):\n\u001B[1;32m    161\u001B[0m         subdir_path \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrefix\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/paginate.py:269\u001B[0m, in \u001B[0;36mPageIterator.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inject_starting_params(current_kwargs)\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 269\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    270\u001B[0m     parsed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extract_parsed_response(response)\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m first_request:\n\u001B[1;32m    272\u001B[0m         \u001B[38;5;66;03m# The first request is handled differently.  We could\u001B[39;00m\n\u001B[1;32m    273\u001B[0m         \u001B[38;5;66;03m# possibly have a resume/starting token that tells us where\u001B[39;00m\n\u001B[1;32m    274\u001B[0m         \u001B[38;5;66;03m# to index into the retrieved page.\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/paginate.py:357\u001B[0m, in \u001B[0;36mPageIterator._make_request\u001B[0;34m(self, current_kwargs)\u001B[0m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_make_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, current_kwargs):\n\u001B[0;32m--> 357\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcurrent_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/client.py:514\u001B[0m, in \u001B[0;36mClientCreator._create_api_method.<locals>._api_call\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    511\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpy_operation_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() only accepts keyword arguments.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    512\u001B[0m     )\n\u001B[1;32m    513\u001B[0m \u001B[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001B[39;00m\n\u001B[0;32m--> 514\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_api_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/client.py:917\u001B[0m, in \u001B[0;36mBaseClient._make_api_call\u001B[0;34m(self, operation_name, api_params)\u001B[0m\n\u001B[1;32m    915\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    916\u001B[0m     apply_request_checksum(request_dict)\n\u001B[0;32m--> 917\u001B[0m     http, parsed_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperation_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_context\u001B[49m\n\u001B[1;32m    919\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    921\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mevents\u001B[38;5;241m.\u001B[39memit(\n\u001B[1;32m    922\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter-call.\u001B[39m\u001B[38;5;132;01m{service_id}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{operation_name}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    923\u001B[0m         service_id\u001B[38;5;241m=\u001B[39mservice_id, operation_name\u001B[38;5;241m=\u001B[39moperation_name\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    928\u001B[0m     context\u001B[38;5;241m=\u001B[39mrequest_context,\n\u001B[1;32m    929\u001B[0m )\n\u001B[1;32m    931\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m300\u001B[39m:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/client.py:940\u001B[0m, in \u001B[0;36mBaseClient._make_request\u001B[0;34m(self, operation_model, request_dict, request_context)\u001B[0m\n\u001B[1;32m    938\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_make_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, operation_model, request_dict, request_context):\n\u001B[1;32m    939\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 940\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_endpoint\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    941\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    942\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mevents\u001B[38;5;241m.\u001B[39memit(\n\u001B[1;32m    943\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter-call-error.\u001B[39m\u001B[38;5;132;01m{service_id}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{operation_name}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    944\u001B[0m                 service_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_service_model\u001B[38;5;241m.\u001B[39mservice_id\u001B[38;5;241m.\u001B[39mhyphenize(),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    948\u001B[0m             context\u001B[38;5;241m=\u001B[39mrequest_context,\n\u001B[1;32m    949\u001B[0m         )\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/endpoint.py:119\u001B[0m, in \u001B[0;36mEndpoint.make_request\u001B[0;34m(self, operation_model, request_dict)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, operation_model, request_dict):\n\u001B[1;32m    114\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[1;32m    115\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMaking request for \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m with params: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    116\u001B[0m         operation_model,\n\u001B[1;32m    117\u001B[0m         request_dict,\n\u001B[1;32m    118\u001B[0m     )\n\u001B[0;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperation_model\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/endpoint.py:198\u001B[0m, in \u001B[0;36mEndpoint._send_request\u001B[0;34m(self, request_dict, operation_model)\u001B[0m\n\u001B[1;32m    196\u001B[0m context \u001B[38;5;241m=\u001B[39m request_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontext\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_retries_context(context, attempts)\n\u001B[0;32m--> 198\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperation_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m success_response, exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_response(\n\u001B[1;32m    200\u001B[0m     request, operation_model, context\n\u001B[1;32m    201\u001B[0m )\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_needs_retry(\n\u001B[1;32m    203\u001B[0m     attempts,\n\u001B[1;32m    204\u001B[0m     operation_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    207\u001B[0m     exception,\n\u001B[1;32m    208\u001B[0m ):\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/endpoint.py:134\u001B[0m, in \u001B[0;36mEndpoint.create_request\u001B[0;34m(self, params, operation_model)\u001B[0m\n\u001B[1;32m    130\u001B[0m     service_id \u001B[38;5;241m=\u001B[39m operation_model\u001B[38;5;241m.\u001B[39mservice_model\u001B[38;5;241m.\u001B[39mservice_id\u001B[38;5;241m.\u001B[39mhyphenize()\n\u001B[1;32m    131\u001B[0m     event_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrequest-created.\u001B[39m\u001B[38;5;132;01m{service_id}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{op_name}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    132\u001B[0m         service_id\u001B[38;5;241m=\u001B[39mservice_id, op_name\u001B[38;5;241m=\u001B[39moperation_model\u001B[38;5;241m.\u001B[39mname\n\u001B[1;32m    133\u001B[0m     )\n\u001B[0;32m--> 134\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event_emitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43memit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mevent_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperation_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moperation_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m prepared_request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_request(request)\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m prepared_request\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/hooks.py:412\u001B[0m, in \u001B[0;36mEventAliaser.emit\u001B[0;34m(self, event_name, **kwargs)\u001B[0m\n\u001B[1;32m    410\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21memit\u001B[39m(\u001B[38;5;28mself\u001B[39m, event_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    411\u001B[0m     aliased_event_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alias_event_name(event_name)\n\u001B[0;32m--> 412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_emitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43memit\u001B[49m\u001B[43m(\u001B[49m\u001B[43maliased_event_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/hooks.py:256\u001B[0m, in \u001B[0;36mHierarchicalEmitter.emit\u001B[0;34m(self, event_name, **kwargs)\u001B[0m\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21memit\u001B[39m(\u001B[38;5;28mself\u001B[39m, event_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    246\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;124;03m    Emit an event by name with arguments passed as keyword args.\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;124;03m             handlers.\u001B[39;00m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 256\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_emit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevent_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/hooks.py:239\u001B[0m, in \u001B[0;36mHierarchicalEmitter._emit\u001B[0;34m(self, event_name, kwargs, stop_on_response)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers_to_call:\n\u001B[1;32m    238\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEvent \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: calling handler \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m, event_name, handler)\n\u001B[0;32m--> 239\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mhandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m     responses\u001B[38;5;241m.\u001B[39mappend((handler, response))\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stop_on_response \u001B[38;5;129;01mand\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/signers.py:105\u001B[0m, in \u001B[0;36mRequestSigner.handler\u001B[0;34m(self, operation_name, request, **kwargs)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(\u001B[38;5;28mself\u001B[39m, operation_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;66;03m# This is typically hooked up to the \"request-created\" event\u001B[39;00m\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;66;03m# from a client's event emitter.  When a new request is created\u001B[39;00m\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;66;03m# this method is invoked to sign the request.\u001B[39;00m\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;66;03m# Don't call this method directly.\u001B[39;00m\n\u001B[0;32m--> 105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msign\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/signers.py:189\u001B[0m, in \u001B[0;36mRequestSigner.sign\u001B[0;34m(self, operation_name, request, region_name, signing_type, expires_in, signing_name)\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m--> 189\u001B[0m \u001B[43mauth\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_auth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/mlops-9eU1RBQD-py3.8/lib/python3.8/site-packages/botocore/auth.py:418\u001B[0m, in \u001B[0;36mSigV4Auth.add_auth\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madd_auth\u001B[39m(\u001B[38;5;28mself\u001B[39m, request):\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcredentials \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 418\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m NoCredentialsError()\n\u001B[1;32m    419\u001B[0m     datetime_now \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mutcnow()\n\u001B[1;32m    420\u001B[0m     request\u001B[38;5;241m.\u001B[39mcontext[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m datetime_now\u001B[38;5;241m.\u001B[39mstrftime(SIGV4_TIMESTAMP)\n",
      "\u001B[0;31mNoCredentialsError\u001B[0m: Unable to locate credentials"
     ]
    }
   ],
   "source": [
    "# set up the mlflow server url and experiment name\n",
    "mlflow_server_uri = \"https://user-pengfei-42041.kub.sspcloud.fr/\"\n",
    "experiment_name = \"pokemon\"\n",
    "version = '5'\n",
    "\n",
    "test_model(mlflow_server_uri,experiment_name,version)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}